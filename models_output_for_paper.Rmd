---
title: "Appendix A: Annotated R Code and Output"
author: "Sofi Sinozich & Rachael Jackson"
date: "12/8/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
# Data tweaks -------------------------------------------------------------
full_data <- readRDS("data/full_data.rds")

full_data$race <- factor(full_data$race,levels=c("White","Black","Hispanic","Other"))
full_data$black <- ifelse(full_data$race=="Black",1,0)
full_data$west <- ifelse(full_data$region=="West",1,0)
full_data$examiner_id_factor <- relevel(factor(full_data$examiner_id,levels=as.character(c(3007,c(3001:3012)[-7]))),ref="3007")
```

Our full code, including initial data wrangling and brief exploratory code is available on GitHub [https://github.com/sofisinozich/SURV617_Final_Project](https://github.com/sofisinozich/SURV617_Final_Project) but we present the key models and diagnostics here.

# Variable selection with glmnet (`$\alpha = 1$` for LASSO)

We tested three different variations, one unweighted, one weighted using the observation weights in `glmnet` and one with weights as a linear predictor. We use `lambda.1se` rather than `lambda.min` to achieve more shrinkage given our suspicion that some of the variables may not be important.

```{r, cache=TRUE}
library(glmnet)
library(glmnetUtils)

health_lasso <- cv.glmnet(health_status2 ~
                            race+ gender + scale(age) + region + time_of_day +
                            scale(systolic_bp) + scale(diastolic_bp) +
                            locomotion + paralysis + impairment + infection +
                            scale(bmi) + scale(weight) + scale(height)+ 
                            scale(rbc_count) + scale(wbc_count) + scale(plt_count) + scale(hemoglobin) +
                            examiner_id_factor,
                          data=full_data,
                          family= binomial(link = "logit"))

# Test with observation weights
health_lasso_weighted <- cv.glmnet(health_status2 ~
                                    race+ gender + scale(age) + region + time_of_day +
                                    scale(systolic_bp) + scale(diastolic_bp) +
                                    locomotion + paralysis + impairment + infection +
                                    scale(bmi) + scale(weight) + scale(height)+ 
                                    scale(rbc_count) + scale(wbc_count) + scale(plt_count) + scale(hemoglobin) +
                                    examiner_id_factor,
                                  weights = WTPFHX6,
                                  data=full_data,
                                  family= binomial(link = "logit"))

# Test with weights as a predictor instead
health_lasso_weightaspredictor <- cv.glmnet(health_status2 ~
                                     scale(WTPFHX6) +
                                     race+ gender + scale(age) + region + time_of_day +
                                     scale(systolic_bp) + scale(diastolic_bp) +
                                     locomotion + paralysis + impairment + infection +
                                     scale(bmi) + scale(weight) + scale(height)+ 
                                     scale(rbc_count) + scale(wbc_count) + scale(plt_count) + scale(hemoglobin) +
                                     examiner_id_factor,
                                   data=full_data,
                                   family= binomial(link = "logit"))

coef(health_lasso,s="lambda.1se")
coef(health_lasso_weighted,s="lambda.1se")
coef(health_lasso_weightaspredictor,s="lambda.1se")
```

# Evaluate the impact of examiner ID further

Even though the results of the regularization seem to suggest that we keep it, we did additional checks to gather additional evidence for an examiner-specific effect. We also double-check the usefulness of weights as a linear predictor based on the LASSO output.

We also adjusted two of our categorical variables to include only dummies for one of the categories based on the previous output, replacing `race` with `black` and `region` with `west`. We also use unscaled age for better interpretability.

```{r}
# Base model - using the selected variables but NO examiner effect
health_model <- glm(health_status2 ~
                      black + gender + age + west +
                      scale(systolic_bp) + scale(diastolic_bp) +
                      locomotion + paralysis + impairment + infection +
                      scale(bmi) + scale(height) +
                      scale(wbc_count) + scale(plt_count) + scale(hemoglobin),
                    data=full_data,
                    family = binomial(link = "logit"))

# Base model limited to those that have examiner IDs
health_model_lim <- glm(health_status2 ~
                      black + gender + age + west +
                      scale(systolic_bp) + scale(diastolic_bp) +
                      locomotion + paralysis + impairment + infection +
                      scale(bmi) + scale(height) +
                      scale(wbc_count) + scale(plt_count) + scale(hemoglobin),
                    data=subset(full_data,!is.na(examiner_id_factor)),
                    family = binomial(link = "logit"))

# Base model WITH examiner
health_model_examiner <- glm(health_status2 ~
                      black + gender + age + west +
                      scale(systolic_bp) + scale(diastolic_bp) +
                      locomotion + paralysis + impairment + infection +
                      scale(bmi) + scale(height) +
                      scale(wbc_count) + scale(plt_count) + scale(hemoglobin) +
                      examiner_id_factor,
                    data=full_data,
                    family = binomial(link = "logit"))

# Double-check whether weights would be useful as predictors
health_model_examiner_weightaspredictor <- glm(health_status2 ~
                                                 scale(WTPFHX6) +
                                                 black + gender + age + west +
                                                 scale(systolic_bp) + scale(diastolic_bp) +
                                                 locomotion + paralysis + impairment + infection +
                                                 scale(bmi) + scale(height) +
                                                 scale(wbc_count) + scale(plt_count) + scale(hemoglobin) +
                                                 examiner_id_factor,
                                               data=full_data,
                                               family = binomial(link = "logit"))

AIC(health_model,health_model_lim,health_model_examiner,health_model_examiner_weightaspredictor)
BIC(health_model,health_model_lim,health_model_examiner,health_model_examiner_weightaspredictor)
# Note that warning is tripped by the health_model (health_model_lim and all others have same n)

summary(health_model_examiner)
```


# Interactions

We wanted to evaluate the usefulness of some interactions related to our research questions. We conclude that adding a interaction between the examiner and gender is worthwhile.

```{r}
health_model_examiner_intgender <- update(health_model_examiner,.~.+examiner_id_factor:gender)
health_model_examiner_intblack <- update(health_model_examiner,.~.+examiner_id_factor:black)
health_model_examiner_intblackgender <- update(health_model_examiner,.~.+examiner_id_factor:gender:black)

AIC(health_model_examiner,health_model_examiner_intgender,health_model_examiner_intblack,health_model_examiner_intblackgender)
# Gender interaction seems to be making the most difference

# Likelihood ratio tests
(health_model_lim$deviance - health_model_examiner$deviance)>qchisq(.95,11)
1-pchisq((health_model_lim$deviance - health_model_examiner$deviance),11)
# This is greater, so we conclude that we should keep the examiner IDs

(health_model_examiner$deviance - health_model_examiner_intgender$deviance)>qchisq(.95,11)
1-pchisq((health_model_examiner$deviance - health_model_examiner_intgender$deviance),11)
# This is greater, so we conclude that we should keep the gender interaction

(health_model_examiner_intgender$deviance - health_model_examiner_intblackgender$deviance) > qchisq(.95,12)
1-pchisq((health_model_examiner_intgender$deviance - health_model_examiner_intblackgender$deviance) ,12)
# This is greater, but really not by much

summary(health_model_examiner_intgender)
```

# Brief diagnostics

```{r}
library(tidyverse)

outcomes <- bind_cols(model.frame(health_model_examiner_intgender), 
                      predicted=ifelse(predict(health_model_examiner_intgender,type="response")>.5,1,0))

outcome_table <- outcomes %>% count(health_status2,predicted) %>% rename(Actual = health_status2, Predicted = predicted)

# Accuracy
outcome_table %>% group_by(Actual == Predicted) %>% summarize(n=sum(n)) %>% mutate(n = n/sum(n))

# Sensitivity
outcome_table %>% group_by(Actual) %>% summarize(Predicted= Predicted,n = n/sum(n)) %>% 
  bind_cols(desc = c("True negative rate", "False positive rate","False negative rate","True positive rate"))

# Pseudo R2
# Per http://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/
1-health_model_examiner_intgender$deviance/health_model_examiner$null.deviance

# Alternative formulation from Statistical Modeling class last year
# Very similar results, though not identical
1-exp((health_model_examiner_intgender$deviance-health_model_examiner_intgender$null.deviance)/dim(model.frame(health_model_examiner_intgender))[1])

# Consider R2 of no examiner
1-health_model_lim$deviance/health_model_lim$null.deviance
```

# Further diagnostics

```{r}
library(tidyverse)
library(broom)

probabilities <- predict(health_model_examiner_intgender, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)

mydata <- model.frame(health_model_examiner_intgender) %>% select(age, "scale(systolic_bp)", "scale(diastolic_bp)","scale(bmi)","scale(wbc_count)","scale(plt_count)","scale(height)", "scale(hemoglobin)") 
predictors <- colnames(mydata)

mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")
# I honestly can't tell if these could be considered roughly linear.

plot(health_model_examiner_intgender, which = 4, id.n = 3)

model.data <- augment(health_model_examiner_intgender) %>% 
  mutate(index = 1:n()) 

model.data %>% top_n(3, .cooksd)

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = health_status2), alpha = .5) +
  theme_bw()

model.data %>% 
  filter(abs(.std.resid) > 3)
# Note: We seem to have 24 influential data points that could be skewing the data.

car::vif(health_model_examiner_intgender)
#Note: We don't seem to have a problematic amount of multicollinearity.
```


# Final model table (*health_model_examiner_intgender*)

```{r echo=FALSE}
library(kableExtra)
library(tidyverse)
library(magrittr)
tableout <- summary(health_model_examiner_intgender)$coef %>% as.data.frame %>% rownames_to_column("Variable") %>% select(-'z value') 
names(tableout) <- c("Variable","Estimate","SE","sig")
tableout %<>% 
  mutate(sigstar = case_when(sig >= 0.1 ~ "",
                         sig < 0.1 & sig >= 0.05 ~ ".",
                         sig < 0.05 & sig >= 0.01 ~ "*",
                         sig < 0.01 & sig >= 0.001 ~ "**",
                         sig < 0.001 ~ "***"))

tableout %>% knitr::kable(digits=3)

# For the main body of the text
tableout %>% knitr::kable(digits=3) %>% save_kable("body_table.html")
```

